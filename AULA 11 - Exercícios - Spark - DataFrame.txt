
* AULA 10 - Exercícios - Spark - DataFrame  *

-------------------------------------------------------------------------
1. Enviar o diretório local “/input/exercises-data/juros_selic”
 para o HDFS em “/user/aluno/maoshie/data”

root@namenode:/# hdfs dfs -ls /user/aluno/maoshie/data/juros_selic
Found 3 items
-rw-r--r--   3 root supergroup       7954 2021-04-10 20:15 /user/aluno/maoshie/data/juros_selic/juros_selic
-rw-r--r--   3 root supergroup      14621 2021-04-10 20:15 /user/aluno/maoshie/data/juros_selic/juros_selic.json
-rw-r--r--   3 root supergroup      12900 2021-04-10 20:15 /user/aluno/maoshie/data/juros_selic/juros_selic.wsdl

-------------------------------------------------------------------------
2. Criar o DataFrame jurosDF para ler o arquivo no 
HDFS “/user/aluno/maoshie/data/juros_selic/juros_selic.json”

#comando:
val jurosDF = spark.read.json("/user/aluno/maoshie/data/juros_selic/juros_selic.json")

jurosDF: org.apache.spark.sql.DataFrame = [data: string, valor: string]

-------------------------------------------------------------------------
3. Visualizar o Schema do jurosDF

scala> jurosDF.printSchema()
root
 |-- data: string (nullable = true)
 |-- valor: string (nullable = true)


-------------------------------------------------------------------------
4. Mostrar os 5 primeiros registros do jutosDF

scala> jurosDF.show(5)
+----------+-----+
|      data|valor|
+----------+-----+
|01/06/1986| 1.27|
|01/07/1986| 1.95|
|01/08/1986| 2.57|
|01/09/1986| 2.94|
|01/10/1986| 1.96|
+----------+-----+
only showing top 5 rows

-------------------------------------------------------------------------
5. Contar a quantidade de registros do jurosDF

scala> jurosDF.count()
res4: Long = 393

-------------------------------------------------------------------------
6. Criar o DataFrame jurosDF10 para filtrar apenas os registros com o 
campo “valor” maior que 10

val jurosDF10 = jurosDF.where("valor > 10")
jurosDF10: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [data: string, valor: string]

-------------------------------------------------------------------------
7. Salvar o DataFrame jurosDF10  como tabela Hive “<nome>.tab_juros_selic”

scala> jurosDF10.write.saveAsTable("maoshie.tab_juros_selic")

-------------------------------------------------------------------------
8. Criar o DataFrame jurosHiveDF para ler a tabela “<nome>.tab_juros_selic”

scala> val jurosHiveDF = spark.read.table("maoshie.tab_juros_selic")
jurosHiveDF: org.apache.spark.sql.DataFrame = [data: string, valor: string]

-------------------------------------------------------------------------
9. Visualizar o Schema do jurosHiveDF

scala> jurosHiveDF.printSchema()
root
 |-- data: string (nullable = true)
 |-- valor: string (nullable = true)

-------------------------------------------------------------------------
10. Mostrar os 5 primeiros registros do jurosHiveDF

scala> jurosHiveDF.show(5)
+----------+-----+ 
|      data|valor|
+----------+-----+
|01/01/1987|11.00|
|01/02/1987|19.61|
|01/03/1987|11.95|
|01/04/1987|15.30|
|01/05/1987|24.63|
+----------+-----+
only showing top 5 rows

-------------------------------------------------------------------------
11. Salvar o DataFrame jurosHiveDF no HDFS no diretório “/user/aluno/nome/data/save_juros” no formato parquet

scala> jurosHiveDF.write.save("/user/aluno/maoshie/data/save_juros")

-------------------------------------------------------------------------
12. Visualizar o save_juros no HDFS

^[[Aroot@namenode:/# hdfs dfs -ls /user/aluno/maoshie/data/save_juros
Found 2 items
-rw-r--r--   2 root supergroup          0 2021-04-10 21:11 /user/aluno/maoshie/data/save_juros/_SUCCESS
-rw-r--r--   2 root supergroup       1419 2021-04-10 21:11 /user/aluno/maoshie/data/save_juros/part-00000-1f865ad5-eaec-43b7-80f5-247b62eac5e6-c000.snappy.parquet

-------------------------------------------------------------------------
13. Criar o DataFrame jurosHDFS para ler o diretório do “save_juros” da questão 8

scala> val jurosHDFS = spark.read.load("/user/aluno/maoshie/data/save_juros")
jurosHDFS: org.apache.spark.sql.DataFrame = [data: string, valor: string]

-------------------------------------------------------------------------
14. Visualizar o Schema do jurosHDFS

scala> jurosHDFS.printSchema()
root
 |-- data: string (nullable = true)
 |-- valor: string (nullable = true)

-------------------------------------------------------------------------
15. Mostrar os 5 primeiros registros do jurosHDFS

scala> jurosHDFS.show(5)
+----------+-----+
|      data|valor|
+----------+-----+
|01/01/1987|11.00|
|01/02/1987|19.61|
|01/03/1987|11.95|
|01/04/1987|15.30|
|01/05/1987|24.63|
+----------+-----+
only showing top 5 rows

-------------------------------------------------------------------------