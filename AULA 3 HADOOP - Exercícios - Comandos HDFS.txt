
* AULA 3 HADOOP - Exercícios - Comandos HDFS

1. Iniciar o cluster de Big Data

    cd docker-bigdata - feito
    docker-compose up -d - feito

2. Baixar os dados dos exercícios do treinamento

    cd input
    sudo git clone https://github.com/rodrigo-reboucas/exercises-data.git - feito

3. Acessar o container do namenode
maoshie@DESKTOP-343S2AC:~/docker-bigdata$ docker exec -it namenode bash
root@namenode:/#

4. Criar a estrutura de pastas apresentada a baixo pelo comando: $ hdfs dfs -ls -R /

user/aluno/maoshie/data
user/aluno/maoshie/recover
user/aluno/maoshie/delete

root@namenode:/# hdfs dfs -ls -R /user/aluno/maoshie/
drwxr-xr-x   - root supergroup          0 2021-04-01 20:23 /user/aluno/maoshie/data
drwxr-xr-x   - root supergroup          0 2021-04-01 20:24 /user/aluno/maoshie/delete
drwxr-xr-x   - root supergroup          0 2021-04-01 20:24 /user/aluno/maoshie/recover
root@namenode:/#

5. Enviar a pasta “/input/exercises-data/escola” e o arquivo

namenode > hdfs   “/input/exercises-data/entrada1.txt” para /user/aluno/maoshie/data (hdfs)
LOCAL > HDFS


6. Mover o arquivo “entrada1.txt” para recover

7. Baixar o arquivo do hdfs “escola/alunos.json” para o sistema local /

8. Deletar a pasta recover

9. Deletar permanentemente o delete

10. Procurar o arquivo “alunos.csv” dentro do /user

11. Mostrar o último 1KB do arquivo “alunos.csv”

12. Mostrar as 2 primeiras linhas do arquivo “alunos.csv”

13. Verificação de soma das informações do arquivo “alunos.csv”

14. Criar um arquivo em branco com o nome de “test” no data

15. Alterar o fator de replicação do arquivo “test” para 2

16. Ver as informações do arquivo “alunos.csv”

17. Exibir o espaço livre do data e o uso do disco